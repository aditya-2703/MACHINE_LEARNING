{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16d6074b",
   "metadata": {},
   "source": [
    "# Face Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "097ab4cf",
   "metadata": {},
   "source": [
    "Face recognition - \n",
    "\n",
    "    -Creating Data \n",
    "        - Face detection\n",
    "            - cascadeclassifier\n",
    "        - Giving label\n",
    "            - lable as input of person name\n",
    "    -Loading Data to model(Knn)\n",
    "    -Predict Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f2a0e64",
   "metadata": {},
   "source": [
    "### For single photo  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "932ac7e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['devanshi'], dtype='<U8')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importing module\n",
    "import numpy as np \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import cv2\n",
    "\n",
    "# loading test case\n",
    "image = cv2.imread(\"dustbin.jpg\")\n",
    "\n",
    "# loading cascadeclassifier\n",
    "obj = cv2.CascadeClassifier(r\"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python39\\Lib\\site-packages\\cv2\\data//haarcascade_frontalface_default.xml\")\n",
    "\n",
    "face= obj.detectMultiScale(image)\n",
    "\n",
    "# getting face axis\n",
    "x,y,w,h = face[0]\n",
    "\n",
    "# cutting face from entire pic\n",
    "actual_face = image[y:y+h,x:x+w]\n",
    "# converting face to gray scale\n",
    "grey_actual_face = cv2.cvtColor(actual_face,cv2.COLOR_BGR2GRAY)\n",
    "# resizing image so all data has proper same dimensions\n",
    "actual_face = cv2.resize(grey_actual_face,(100,100))\n",
    "\n",
    "# loading saved data\n",
    "data =np.load(\"face_data.npy\")\n",
    "\n",
    "# fetching features and lables\n",
    "features = data[:,1:].astype(int)\n",
    "lable = data[:,0]\n",
    "\n",
    "# initialize model\n",
    "model = KNeighborsClassifier()\n",
    "\n",
    "# give data to train model \n",
    "model.fit(features,lable)\n",
    "\n",
    "# flattening image\n",
    "flatten_img = actual_face.flatten()\n",
    "# predicting image name\n",
    "prediction = model.predict([flatten_img])\n",
    "\n",
    "prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3436e2e",
   "metadata": {},
   "source": [
    "### For realtime video capturing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f95e51b5",
   "metadata": {},
   "source": [
    "Vdo = multiple_fram of images so simply just modify this above code and you realtime video capturing done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b730c2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing usefull modules\n",
    "import numpy as np \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import cv2\n",
    "\n",
    "# open vdo capturing stream\n",
    "vdo = cv2.VideoCapture(0)\n",
    "# initialize the loop which capture multiple frames so it act like vdo\n",
    "while True:\n",
    "    # taking flag and image from this stream\n",
    "    # flag is just boolean variable which return true if there is no problem with vdo capturing else false\n",
    "    flag, image = vdo.read()\n",
    "        \n",
    "    # so if there is no problem with vdo streaming then will do our work\n",
    "    if flag:\n",
    "        # initialize the cascadeclassifier\n",
    "        obj = cv2.CascadeClassifier(r\"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python39\\Lib\\site-packages\\cv2\\data//haarcascade_frontalface_default.xml\")\n",
    "        \n",
    "        # fetching faces        \n",
    "        faces= obj.detectMultiScale(image)\n",
    "        # looping for each face from all faces\n",
    "        for face in faces:\n",
    "            x,y,w,h = face\n",
    "            \n",
    "            # extracting face axis\n",
    "            actual_face = image[y:y+h,x:x+w]\n",
    "            \n",
    "# drawing rectangle for just make sure that detection is happning right                     \n",
    "            cv2.rectangle(image,(x,y),(x+w,y+h),(255,0,0),1)\n",
    "\n",
    "# convert actual face to gray scals             \n",
    "\n",
    "            actual_face = cv2.cvtColor(actual_face,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# resize the dimension\n",
    "            actual_face = cv2.resize(actual_face,(100,100))\n",
    "\n",
    "# loading data for training\n",
    "            data =np.load(\"face_data.npy\")\n",
    "\n",
    "# fetching features and lables\n",
    "\n",
    "            features = data[:,1:].astype(int)\n",
    "            lable = data[:,0]\n",
    "\n",
    "# building model\n",
    "            model = KNeighborsClassifier()\n",
    "\n",
    "# train model with these data\n",
    "            model.fit(features,lable)\n",
    "\n",
    "# flatten all image frame\n",
    "            flatten_img = actual_face.flatten()\n",
    "# getting prediction from model\n",
    "            prediction = model.predict([flatten_img])\n",
    "\n",
    "# show this prediction as text to window \n",
    "            cv2.putText(image,prediction[0],(x,y-10),cv2.FONT_HERSHEY_SIMPLEX,2,(0,255,0),2)\n",
    "        \n",
    "# showing the window         \n",
    "        cv2.imshow(\"image\",image)\n",
    "# for quite the windo        \n",
    "        key = cv2.waitKey(1)\n",
    "        if key==ord(\"q\"):\n",
    "            break\n",
    "\n",
    "vdo.release()\n",
    "cv2.destroyallwindows()\n",
    "               "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
